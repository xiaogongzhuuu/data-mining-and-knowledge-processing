import streamlit as st
import time
import os
os.environ['HF_HOME'] = './hf_cache'
os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '0'
os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'
os.environ['TRANSFORMERS_OFFLINE'] = '1'
os.environ['HF_DATASETS_OFFLINE'] = '1'


# Import functions and config from other modules
from config import (
    DATA_FILE, EMBEDDING_MODEL_NAME, GENERATION_MODEL_NAME, TOP_K,
    MAX_ARTICLES_TO_INDEX, MILVUS_LITE_DATA_PATH, COLLECTION_NAME,
    id_to_doc_map, OLLAMA_MODEL # Import the global map and ollama config
)
from data_utils import load_data
from models import load_embedding_model, load_generation_model
# Import ChromaDB functions
from chroma_utils import get_chroma_client, setup_chroma_collection, index_data_if_needed, search_similar_documents
from rag_core import generate_answer
# Import optimization modules
from retrieval_optimizer import hybrid_search, rerank_documents, remove_duplicate_documents

# --- Streamlit UI è®¾ç½® ---
st.set_page_config(layout="wide")
st.title("ğŸ“„ åŒ»ç–— RAG ç³»ç»Ÿ (ChromaDB + Ollama)")
st.markdown(f"ä½¿ç”¨ ChromaDB, `{EMBEDDING_MODEL_NAME}`, å’Œ Ollama `{OLLAMA_MODEL}`ã€‚")

# --- åˆå§‹åŒ–ä¸ç¼“å­˜ ---
# è·å– ChromaDB å®¢æˆ·ç«¯ (å¦‚æœæœªç¼“å­˜åˆ™åˆå§‹åŒ–)
chroma_client = get_chroma_client()

if chroma_client:
    # è®¾ç½® collection (å¦‚æœæœªç¼“å­˜åˆ™åˆ›å»º/åŠ è½½ç´¢å¼•)
    collection_is_ready = setup_chroma_collection(chroma_client)

    # åŠ è½½æ¨¡å‹ (ç¼“å­˜)
    embedding_model = load_embedding_model(EMBEDDING_MODEL_NAME)
    generation_model, tokenizer = load_generation_model(GENERATION_MODEL_NAME)

    # æ£€æŸ¥æ‰€æœ‰ç»„ä»¶æ˜¯å¦æˆåŠŸåŠ è½½
    # å¯¹äº ollamaï¼Œtokenizer å¯ä»¥ä¸º None
    models_loaded = embedding_model and generation_model

    if collection_is_ready and models_loaded:
        # åŠ è½½æ•°æ® (æœªç¼“å­˜)
        pubmed_data = load_data(DATA_FILE)

        # å¦‚æœéœ€è¦åˆ™ç´¢å¼•æ•°æ® (è¿™ä¼šå¡«å…… id_to_doc_map)
        if pubmed_data:
            indexing_successful = index_data_if_needed(chroma_client, pubmed_data, embedding_model)
        else:
            st.warning(f"æ— æ³•ä» {DATA_FILE} åŠ è½½æ•°æ®ã€‚è·³è¿‡ç´¢å¼•ã€‚")
            indexing_successful = False # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œåˆ™è§†ä¸ºä¸æˆåŠŸ

        st.divider()

        # --- RAG äº¤äº’éƒ¨åˆ† ---
        if not indexing_successful and not id_to_doc_map:
             st.error("æ•°æ®ç´¢å¼•å¤±è´¥æˆ–ä¸å®Œæ•´ï¼Œä¸”æ²¡æœ‰æ–‡æ¡£æ˜ å°„ã€‚RAG åŠŸèƒ½å·²ç¦ç”¨ã€‚")
        else:
            query = st.text_input("è¯·æå‡ºå…³äºå·²ç´¢å¼•åŒ»ç–—æ–‡ç« çš„é—®é¢˜:", key="query_input")

            if st.button("è·å–ç­”æ¡ˆ", key="submit_button") and query:
                start_time = time.time()

                # 1. ä½¿ç”¨æ··åˆæ£€ç´¢æœç´¢ç›¸å…³æ–‡æ¡£
                with st.spinner("æ­£åœ¨æœç´¢ç›¸å…³æ–‡æ¡£..."):
                    retrieved_docs, distances = hybrid_search(
                        query, chroma_client, embedding_model, top_k=TOP_K
                    )

                if not retrieved_docs:
                    st.warning("åœ¨æ•°æ®åº“ä¸­æ‰¾ä¸åˆ°ç›¸å…³æ–‡æ¡£ã€‚")
                else:
                    # 2. å»é‡
                    retrieved_docs = remove_duplicate_documents(retrieved_docs)

                    if not retrieved_docs:
                        st.error("æ£€ç´¢ç»“æœä¸ºç©ºã€‚")
                    else:
                        st.subheader("æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æ–‡æ¡£:")
                        for i, doc in enumerate(retrieved_docs):
                            # å¦‚æœè·ç¦»å¯ç”¨åˆ™æ˜¾ç¤ºï¼Œå¦åˆ™åªæ˜¾ç¤º ID
                            dist_str = f", ç›¸ä¼¼åº¦: {distances[i]:.4f}" if distances and i < len(distances) else ""
                            # ä» id_to_doc_map ä¸­æŸ¥æ‰¾æ–‡æ¡£ ID
                            doc_id = None
                            for did, ddoc in id_to_doc_map.items():
                                if ddoc == doc:
                                    doc_id = did
                                    break
                            doc_id_str = f" [ID: {doc_id}]" if doc_id is not None else ""
                            with st.expander(f"æ–‡æ¡£ {i+1}{dist_str}{doc_id_str} - {doc['title'][:60]}"):
                                st.write(f"**æ–‡æ¡£ ID:** {doc_id if doc_id is not None else 'æœªçŸ¥'}")
                                st.write(f"**æ ‡é¢˜:** {doc['title']}")
                                st.write(f"**æ¥æº:** {doc.get('source_file', 'æœªçŸ¥')}")
                                st.write(f"**æ‘˜è¦:** {doc['abstract'][:500]}...")

                        st.divider()

                        # 3. ç”Ÿæˆç­”æ¡ˆ
                        st.subheader("ç”Ÿæˆçš„ç­”æ¡ˆ:")
                        with st.spinner("æ­£åœ¨æ ¹æ®ä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆ..."):
                            answer = generate_answer(query, retrieved_docs, generation_model, tokenizer)
                            st.write(answer)

                end_time = time.time()
                st.info(f"æ€»è€—æ—¶: {end_time - start_time:.2f} ç§’")

    else:
        st.error("åŠ è½½æ¨¡å‹æˆ–è®¾ç½® ChromaDB collection å¤±è´¥ã€‚è¯·æ£€æŸ¥æ—¥å¿—å’Œé…ç½®ã€‚")
else:
    st.error("åˆå§‹åŒ– ChromaDB å®¢æˆ·ç«¯å¤±è´¥ã€‚è¯·æ£€æŸ¥æ—¥å¿—ã€‚")


# --- é¡µè„š/ä¿¡æ¯ä¾§è¾¹æ  ---
st.sidebar.header("ç³»ç»Ÿé…ç½®")
st.sidebar.markdown(f"**å‘é‡å­˜å‚¨:** ChromaDB")
st.sidebar.markdown(f"**æ•°æ®è·¯å¾„:** `{MILVUS_LITE_DATA_PATH}`")
st.sidebar.markdown(f"**Collection:** `{COLLECTION_NAME}`")
st.sidebar.markdown(f"**æ•°æ®æ–‡ä»¶:** `{DATA_FILE}`")
st.sidebar.markdown(f"**åµŒå…¥æ¨¡å‹:** `{EMBEDDING_MODEL_NAME}`")
st.sidebar.markdown(f"**ç”Ÿæˆæ¨¡å‹:** Ollama `{OLLAMA_MODEL}`")
st.sidebar.markdown(f"**æœ€å¤§ç´¢å¼•æ•°:** `{MAX_ARTICLES_TO_INDEX}`")
st.sidebar.markdown(f"**æ£€ç´¢ Top K:** `{TOP_K}`")