import streamlit as st
import time
import os
os.environ['HF_HOME'] = './hf_cache'
os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = '0'
os.environ['HF_HUB_DISABLE_TELEMETRY'] = '1'
os.environ['TRANSFORMERS_OFFLINE'] = '1'
os.environ['HF_DATASETS_OFFLINE'] = '1'


# Import functions and config from other modules
from config import (
    DATA_FILE, EMBEDDING_MODEL_NAME, GENERATION_MODEL_NAME, TOP_K,
    MAX_ARTICLES_TO_INDEX, MILVUS_LITE_DATA_PATH, COLLECTION_NAME,
    id_to_doc_map, OLLAMA_MODEL # Import the global map and ollama config
)
from data_utils import load_data
from models import load_embedding_model, load_generation_model
# Import ChromaDB functions
from chroma_utils import get_chroma_client, setup_chroma_collection, index_data_if_needed
from rag_core import generate_answer
# Import optimization modules
from retrieval_optimizer import hybrid_search, remove_duplicate_documents

# --- Streamlit UI è®¾ç½® ---
st.set_page_config(layout="wide")
st.title("ğŸ“„ åŒ»ç–— RAG ç³»ç»Ÿ (ChromaDB + Ollama)")
st.markdown(f"ä½¿ç”¨ ChromaDB, `{EMBEDDING_MODEL_NAME}`, å’Œ Ollama `{OLLAMA_MODEL}`ã€‚")

# --- åˆå§‹åŒ–å˜é‡ï¼ˆç¡®ä¿åœ¨æ‰€æœ‰ä»£ç è·¯å¾„ä¸­éƒ½æœ‰å®šä¹‰ï¼‰---
embedding_loaded = False
generation_loaded = False
collection_is_ready = False

# --- åˆå§‹åŒ–ä¸ç¼“å­˜ ---
# è·å– ChromaDB å®¢æˆ·ç«¯ (å¦‚æœæœªç¼“å­˜åˆ™åˆå§‹åŒ–)
chroma_client = get_chroma_client()

if chroma_client:
    # è®¾ç½® collection (å¦‚æœæœªç¼“å­˜åˆ™åˆ›å»º/åŠ è½½ç´¢å¼•)
    collection_is_ready = setup_chroma_collection(chroma_client)

    # åŠ è½½æ¨¡å‹ (ç¼“å­˜)
    embedding_model = load_embedding_model(EMBEDDING_MODEL_NAME)
    generation_model, tokenizer = load_generation_model(GENERATION_MODEL_NAME)

    # æ£€æŸ¥ç»„ä»¶æ˜¯å¦æˆåŠŸåŠ è½½
    # embedding_model å¿…é¡»å¯ç”¨ï¼Œgeneration_model å¯é€‰ï¼ˆå¯ä»¥åœ¨æœç´¢æ¨¡å¼ä¸‹å·¥ä½œï¼‰
    embedding_loaded = embedding_model is not None
    generation_loaded = generation_model is not None
    
    if collection_is_ready and embedding_loaded:
        # åŠ è½½æ•°æ® (æœªç¼“å­˜)
        pubmed_data = load_data(DATA_FILE)

        # å¦‚æœéœ€è¦åˆ™ç´¢å¼•æ•°æ® (è¿™ä¼šå¡«å…… id_to_doc_map)
        if pubmed_data:
            indexing_successful = index_data_if_needed(chroma_client, pubmed_data, embedding_model)
        else:
            st.warning(f"æ— æ³•ä» {DATA_FILE} åŠ è½½æ•°æ®ã€‚è·³è¿‡ç´¢å¼•ã€‚")
            indexing_successful = False # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œåˆ™è§†ä¸ºä¸æˆåŠŸ

        st.divider()

        # --- RAG äº¤äº’éƒ¨åˆ† ---
        if not indexing_successful and not id_to_doc_map:
             st.error("æ•°æ®ç´¢å¼•å¤±è´¥æˆ–ä¸å®Œæ•´ï¼Œä¸”æ²¡æœ‰æ–‡æ¡£æ˜ å°„ã€‚RAG åŠŸèƒ½å·²ç¦ç”¨ã€‚")
        else:
            # æ˜¾ç¤ºå½“å‰æ¨¡å¼ä¿¡æ¯
            if generation_loaded:
                st.success("âœ… ç³»ç»Ÿå¤„äºå®Œæ•´ RAG æ¨¡å¼ï¼ˆæœç´¢ + ç”Ÿæˆï¼‰")
            else:
                st.info("ğŸ” ç³»ç»Ÿå¤„äºæœç´¢æ¨¡å¼ï¼ˆä»…æ£€ç´¢ï¼Œç”ŸæˆåŠŸèƒ½ä¸å¯ç”¨ï¼‰")
            
            query = st.text_input("è¯·æå‡ºå…³äºå·²ç´¢å¼•åŒ»ç–—æ–‡ç« çš„é—®é¢˜:", key="query_input")

            if st.button("æœç´¢", key="submit_button") and query:
                start_time = time.time()

                # 1. ä½¿ç”¨æ··åˆæ£€ç´¢æœç´¢ç›¸å…³æ–‡æ¡£
                with st.spinner("æ­£åœ¨æœç´¢ç›¸å…³æ–‡æ¡£..."):
                    retrieved_docs, distances = hybrid_search(
                        query, chroma_client, embedding_model, top_k=TOP_K
                    )

                if not retrieved_docs:
                    st.warning("åœ¨æ•°æ®åº“ä¸­æ‰¾ä¸åˆ°ç›¸å…³æ–‡æ¡£ã€‚")
                else:
                    # 2. å»é‡
                    retrieved_docs = remove_duplicate_documents(retrieved_docs)

                    if not retrieved_docs:
                        st.error("æ£€ç´¢ç»“æœä¸ºç©ºã€‚")
                    else:
                        st.subheader("æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æ–‡æ¡£:")
                        for i, doc in enumerate(retrieved_docs):
                            # å¦‚æœè·ç¦»å¯ç”¨åˆ™æ˜¾ç¤ºï¼Œå¦åˆ™åªæ˜¾ç¤º ID
                            dist_str = f", ç›¸ä¼¼åº¦: {distances[i]:.4f}" if distances and i < len(distances) else ""
                            # ä» id_to_doc_map ä¸­æŸ¥æ‰¾æ–‡æ¡£ ID
                            doc_id = None
                            for did, ddoc in id_to_doc_map.items():
                                if ddoc == doc:
                                    doc_id = did
                                    break
                            doc_id_str = f" [ID: {doc_id}]" if doc_id is not None else ""
                            with st.expander(f"æ–‡æ¡£ {i+1}{dist_str}{doc_id_str} - {doc['title'][:60]}"):
                                st.write(f"**æ–‡æ¡£ ID:** {doc_id if doc_id is not None else 'æœªçŸ¥'}")
                                st.write(f"**æ ‡é¢˜:** {doc['title']}")
                                st.write(f"**æ¥æº:** {doc.get('source_file', 'æœªçŸ¥')}")
                                st.write(f"**æ‘˜è¦:** {doc['abstract'][:500]}...")

                        st.divider()

                        # 3. ç”Ÿæˆç­”æ¡ˆï¼ˆå¦‚æœç”Ÿæˆæ¨¡å‹å¯ç”¨ï¼‰
                        if generation_loaded:
                            st.subheader("ç”Ÿæˆçš„ç­”æ¡ˆ:")
                            with st.spinner("æ­£åœ¨æ ¹æ®ä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆ..."):
                                answer = generate_answer(query, retrieved_docs, generation_model, tokenizer)
                                st.write(answer)
                        else:
                            st.info("ğŸ’¡ ç”ŸæˆåŠŸèƒ½ä¸å¯ç”¨ã€‚è¯·å¯åŠ¨ Ollama æœåŠ¡ä»¥å¯ç”¨ç­”æ¡ˆç”ŸæˆåŠŸèƒ½ã€‚")

                end_time = time.time()
                st.info(f"æ€»è€—æ—¶: {end_time - start_time:.2f} ç§’")

    else:
        if not embedding_loaded:
            st.error("âŒ åµŒå…¥æ¨¡å‹åŠ è½½å¤±è´¥ã€‚æ— æ³•ç»§ç»­ã€‚")
        if not collection_is_ready:
            st.error("âŒ ChromaDB collection è®¾ç½®å¤±è´¥ã€‚è¯·æ£€æŸ¥æ—¥å¿—ã€‚")
else:
    st.error("âŒ åˆå§‹åŒ– ChromaDB å®¢æˆ·ç«¯å¤±è´¥ã€‚è¯·æ£€æŸ¥æ—¥å¿—ã€‚")


# --- é¡µè„š/ä¿¡æ¯ä¾§è¾¹æ  ---
st.sidebar.header("ç³»ç»Ÿé…ç½®")
st.sidebar.markdown(f"**å‘é‡å­˜å‚¨:** ChromaDB")
st.sidebar.markdown(f"**æ•°æ®è·¯å¾„:** `{MILVUS_LITE_DATA_PATH}`")
st.sidebar.markdown(f"**Collection:** `{COLLECTION_NAME}`")
st.sidebar.markdown(f"**æ•°æ®æ–‡ä»¶:** `{DATA_FILE}`")
st.sidebar.markdown(f"**åµŒå…¥æ¨¡å‹:** `{EMBEDDING_MODEL_NAME}`")
st.sidebar.markdown(f"**ç”Ÿæˆæ¨¡å‹:** Ollama `{OLLAMA_MODEL}`")
st.sidebar.markdown(f"**æœ€å¤§ç´¢å¼•æ•°:** `{MAX_ARTICLES_TO_INDEX}`")
st.sidebar.markdown(f"**æ£€ç´¢ Top K:** `{TOP_K}`")

st.sidebar.header("æ¨¡å¼ä¿¡æ¯")
if generation_loaded:
    st.sidebar.success("âœ… å®Œæ•´ RAG æ¨¡å¼")
else:
    st.sidebar.warning("ğŸ” æœç´¢æ¨¡å¼ï¼ˆæ— ç”Ÿæˆï¼‰")
    st.sidebar.info("å¯åŠ¨ Ollama: `ollama serve`")