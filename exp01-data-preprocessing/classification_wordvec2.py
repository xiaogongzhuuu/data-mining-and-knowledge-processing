import os
import math
import re
import numpy as np
import pandas as pd
from gensim.models import Word2Vec
from nltk.tokenize import word_tokenize
import nltk
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib

# ç¡®ä¿åˆ†è¯èµ„æºå°±ç»ª
nltk.download("punkt")


# -------- 0. Mac/Windows ä¸­æ–‡å­—ä½“è‡ªåŠ¨é€‚é…è®¾ç½® --------
def set_chinese_font():
    """
    è‡ªåŠ¨é€‰æ‹©ç³»ç»Ÿæ”¯æŒçš„ä¸­æ–‡å­—ä½“ï¼Œä¼˜å…ˆé€‚é… Mac
    """
    # å¸¸è§ä¸­æ–‡å­—ä½“åˆ—è¡¨ï¼Œä¼˜å…ˆçº§ï¼šMacè‹¹æ–¹ -> Macé»‘ä½“ -> Winé»‘ä½“ -> Winé›…é»‘
    font_list = ['PingFang SC', 'Heiti SC', 'STHeiti', 'SimHei', 'Microsoft YaHei', 'SimSun']

    # è·å–å½“å‰ç³»ç»Ÿæ‰€æœ‰å¯ç”¨å­—ä½“
    import matplotlib.font_manager
    available_fonts = set(f.name for f in matplotlib.font_manager.fontManager.ttflist)

    found_font = False
    for font in font_list:
        if font in available_fonts:
            matplotlib.rcParams['font.sans-serif'] = [font]
            matplotlib.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜
            print(f"âœ… å·²å¯ç”¨ä¸­æ–‡å­—ä½“: {font}")
            found_font = True
            break

    if not found_font:
        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œå°è¯•è®¾ç½®é€šç”¨ sans-serifï¼Œå¹¶è­¦å‘Š
        matplotlib.rcParams['font.sans-serif'] = ['sans-serif']
        print("âš ï¸ æœªæ£€æµ‹åˆ°å¸¸ç”¨ä¸­æ–‡å­—ä½“ï¼Œå›¾è¡¨ä¸­æ–‡å¯èƒ½ä¼šæ˜¾ç¤ºä¹±ç ï¼Œè¯·æ£€æŸ¥ç³»ç»Ÿå­—ä½“åº“ã€‚")


# -------- 1. æ–‡æœ¬é¢„å¤„ç† --------
def preprocess_text(text):
    if text is None:
        text = ""
    elif isinstance(text, float):
        text = "" if math.isnan(text) else str(text)
    else:
        text = str(text)
    text = text.lower()
    text = re.sub(r"[^\w\s]", "", text)
    return word_tokenize(text)


# -------- 2. è¯»æ•°æ® --------
def load_data(csv_name="test.csv"):
    base_dir = os.path.dirname(os.path.abspath(__file__))
    csv_path = os.path.join(base_dir, csv_name)
    df = pd.read_csv(csv_path)
    df["text"] = (df.iloc[:, 1].astype(str).fillna("") + " " + df.iloc[:, 2].astype(str).fillna(""))
    labels_raw = df.iloc[:, 0].values
    y = np.array([0 if lab == 1 else 1 for lab in labels_raw], dtype=int)
    return df["text"].tolist(), y


# -------- 3. æ–‡æ¡£å‘é‡åŒ– --------
def get_document_vector(tokens, model, vector_size=100):
    vectors = []
    for w in tokens:
        if w in model.wv:
            vectors.append(model.wv[w])
    if not vectors:
        return np.zeros(vector_size, dtype=float)
    return np.mean(vectors, axis=0)


# -------- 4. ä¸»æµç¨‹ --------
def main():
    base_dir = os.path.dirname(os.path.abspath(__file__))

    # 4.1 åŠ è½½æ¨¡å‹
    model_path = os.path.join(base_dir, "word2vec_sentiment.model")
    print(f"ğŸ‘‰ æ­£åœ¨åŠ è½½ Word2Vec æ¨¡å‹: {model_path}")
    try:
        model = Word2Vec.load(model_path)
    except FileNotFoundError:
        print("âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œå®éªŒä¸€è®­ç»ƒä»£ç ã€‚")
        return
    vector_size = model.vector_size

    # 4.2 åŠ è½½æ•°æ®
    print("ğŸ‘‰ æ­£åœ¨åŠ è½½æ–‡æœ¬å’Œæ ‡ç­¾...")
    texts, y = load_data("test.csv")

    # 4.3 æ„é€ å‘é‡
    print("ğŸ‘‰ æ­£åœ¨æ„é€ æ–‡æ¡£å‘é‡ X ...")
    doc_vectors = [get_document_vector(preprocess_text(t), model, vector_size) for t in texts]
    X = np.array(doc_vectors)

    # 4.4 åˆ’åˆ†æ•°æ®é›†
    print("ğŸ‘‰ åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†...")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    # 4.5 æ ‡å‡†åŒ–
    print("ğŸ‘‰ ç‰¹å¾æ ‡å‡†åŒ–...")
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    # 4.6 è®­ç»ƒ
    print("ğŸ‘‰ è®­ç»ƒ Logistic Regression...")
    clf = LogisticRegression(max_iter=1000, n_jobs=-1, solver="liblinear", random_state=42)
    clf.fit(X_train, y_train)

    # 4.7 è¯„ä¼°
    print("ğŸ‘‰ è¯„ä¼°æ¨¡å‹...")
    y_pred = clf.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    print(f"\nğŸ¯ æµ‹è¯•é›† Accuracy: {acc:.4f}\n")
    print(classification_report(y_test, y_pred, target_names=["Negative", "Positive"], digits=4))

    # =======================================================
    # ğŸ‘‡ğŸ‘‡ğŸ‘‡ é‡ç‚¹ä¼˜åŒ–ï¼šç»˜å›¾éƒ¨åˆ† ğŸ‘‡ğŸ‘‡ğŸ‘‡
    # =======================================================

    # è®¾ç½®ä¸­æ–‡å­—ä½“
    set_chinese_font()

    cm = confusion_matrix(y_test, y_pred)

    # 1. æ„é€ é«˜çº§æ ‡ç­¾ (Label + Count + Percentage)
    # å¯¹åº”æ··æ·†çŸ©é˜µçš„å››ä¸ªæ ¼å­ï¼š[TN, FP], [FN, TP]
    group_names = [
        'çœŸè´Ÿç±» (TN)\næ­£ç¡®é¢„æµ‹å·®è¯„',  # 0,0
        'å‡æ­£ç±» (FP)\nå·®è¯„è¯¯åˆ¤ä¸ºå¥½è¯„',  # 0,1
        'å‡è´Ÿç±» (FN)\nå¥½è¯„è¯¯åˆ¤ä¸ºå·®è¯„',  # 1,0
        'çœŸæ­£ç±» (TP)\næ­£ç¡®é¢„æµ‹å¥½è¯„'  # 1,1
    ]

    group_counts = ["{0:0.0f}".format(value) for value in cm.flatten()]
    group_percentages = ["{0:.2%}".format(value) for value in cm.flatten() / np.sum(cm)]

    # ç»„åˆæ–‡å­—
    labels = [f"{v1}\n{v2}\n({v3})" for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]
    labels = np.asarray(labels).reshape(2, 2)

    # 2. ç»˜å›¾
    plt.figure(figsize=(9, 7), dpi=120)  # å¢åŠ å°ºå¯¸å’Œåˆ†è¾¨ç‡

    # ä½¿ç”¨ seaborn heatmap
    ax = sns.heatmap(
        cm,
        annot=labels,
        fmt='',  # å¿…é¡»ä¸ºç©ºï¼Œå› ä¸ºæˆ‘ä»¬æ‰‹åŠ¨æ„é€ äº† labels å­—ç¬¦ä¸²
        cmap='Blues',  # è“è‰²ç³»ï¼Œä¸“ä¸šä¸”æ¸…æ™°
        cbar=True,
        xticklabels=["é¢„æµ‹ä¸ºå·®è¯„ (Neg)", "é¢„æµ‹ä¸ºå¥½è¯„ (Pos)"],
        yticklabels=["å®é™…ä¸ºå·®è¯„ (Neg)", "å®é™…ä¸ºå¥½è¯„ (Pos)"],
        annot_kws={"size": 11, "weight": "bold"}  # å­—ä½“åŠ ç²—
    )

    # 3. è°ƒæ•´æ ‡é¢˜å’Œè½´æ ‡ç­¾
    plt.title(f"æƒ…æ„Ÿåˆ†ç±»æ··æ·†çŸ©é˜µ\n(Logistic Regression, Accuracy: {acc:.2%})", fontsize=15, fontweight='bold', pad=20)
    plt.xlabel("æ¨¡å‹é¢„æµ‹ç»“æœ", fontsize=12, labelpad=10)
    plt.ylabel("çœŸå®æ ‡ç­¾", fontsize=12, labelpad=10)

    # è°ƒæ•´åˆ»åº¦å­—ä½“
    plt.xticks(fontsize=10)
    plt.yticks(fontsize=10, rotation=0)  # yè½´æ–‡å­—æ¨ªå‘æ˜¾ç¤º

    plt.tight_layout()

    out_path = os.path.join(base_dir, "confusion_matrix_final.png")
    plt.savefig(out_path, dpi=300)
    print(f"âœ… ä¼˜åŒ–åçš„æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ°: {out_path}")
    plt.show()


if __name__ == "__main__":
    main()