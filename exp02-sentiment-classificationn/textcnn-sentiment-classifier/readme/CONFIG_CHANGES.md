# é…ç½®ä¿®æ”¹è¯´æ˜

## ğŸ“ å·²ä¿®æ”¹çš„é…ç½®

### 1. è®­ç»ƒæ ·æœ¬æ•°
```python
MAX_TRAIN_SAMPLES = 10000  # ä½¿ç”¨10000æ¡æ ·æœ¬è¿›è¡Œè®­ç»ƒ
```
- **ä¿®æ”¹å‰**: `None` (ä½¿ç”¨å…¨éƒ¨æ•°æ®ï¼Œçº¦360ä¸‡æ¡)
- **ä¿®æ”¹å**: `10000` (ä½¿ç”¨1ä¸‡æ¡æ ·æœ¬)
- **ç›®çš„**: å¿«é€Ÿè®­ç»ƒï¼ŒèŠ‚çœæ—¶é—´

### 2. å‡è¡¡é‡‡æ ·
```python
BALANCE_TRAIN_DATA = True  # æ˜¯å¦å‡è¡¡æ­£è´Ÿæ ·æœ¬
```
- **æ–°å¢é…ç½®é¡¹**
- **æ•ˆæœ**: è‡ªåŠ¨ä»è®­ç»ƒé›†ä¸­å‡è¡¡é‡‡æ ·
  - è´Ÿé¢æ ·æœ¬: 5000æ¡
  - æ­£é¢æ ·æœ¬: 5000æ¡
  - æ€»è®¡: 10000æ¡

### 3. è®­ç»ƒè½®æ•°
```python
NUM_EPOCHS = 15  # è®­ç»ƒè½®æ•°ï¼ˆå¢åŠ åˆ°15è½®ï¼‰
```
- **ä¿®æ”¹å‰**: `10`
- **ä¿®æ”¹å**: `15`
- **ç›®çš„**: å°æ•°æ®é›†å¯èƒ½éœ€è¦æ›´å¤šè½®æ¬¡æ‰èƒ½å……åˆ†è®­ç»ƒ

## ğŸ”„ æ•°æ®é‡‡æ ·æµç¨‹

### åŸå§‹æ•°æ®
```
è®­ç»ƒé›†: ~3,600,000 æ¡è¯„è®º
  - è´Ÿé¢ (label=1): ~1,800,000 æ¡
  - æ­£é¢ (label=2): ~1,800,000 æ¡
```

### é‡‡æ ·åæ•°æ®
```
è®­ç»ƒé›†: 10,000 æ¡è¯„è®º
  - è´Ÿé¢ (label=0): 5,000 æ¡
  - æ­£é¢ (label=1): 5,000 æ¡
  - åˆ†å¸ƒ: 50% : 50% (å®Œå…¨å‡è¡¡)
```

### éªŒè¯é›†å’Œæµ‹è¯•é›†
```
éªŒè¯é›†: ~1,001 æ¡ (ä¸å˜)
æµ‹è¯•é›†: ~1,001 æ¡ (ä¸å˜)
```

## âš™ï¸ å…¶ä»–å…³é”®é…ç½®

ä¿æŒé»˜è®¤å€¼ï¼š

```python
# æ¨¡å‹é…ç½®
EMBEDDING_DIM = 300          # è¯å‘é‡ç»´åº¦
NUM_FILTERS = 100            # å·ç§¯æ ¸æ•°é‡
FILTER_SIZES = [3, 4, 5]     # çª—å£å¤§å°

# è®­ç»ƒé…ç½®
BATCH_SIZE = 64              # æ‰¹æ¬¡å¤§å°
LEARNING_RATE = 0.001        # å­¦ä¹ ç‡
DROPOUT_RATE = 0.5           # Dropout

# æ•°æ®é…ç½®
MAX_SEQ_LENGTH = 256         # æœ€å¤§åºåˆ—é•¿åº¦
MAX_VOCAB_SIZE = 50000       # è¯è¡¨å¤§å°
MIN_WORD_FREQ = 2            # æœ€å°è¯é¢‘
```

## ğŸš€ å¼€å§‹è®­ç»ƒ

### æ–¹å¼1: ç›´æ¥è®­ç»ƒ
```bash
cd textcnn-sentiment-classifier
python train.py
```

### æ–¹å¼2: å…ˆæµ‹è¯•é…ç½®
```bash
# æµ‹è¯•æ•°æ®åŠ è½½å’Œå‡è¡¡é‡‡æ ·
python test_config.py

# ç¡®è®¤æ— è¯¯åå¼€å§‹è®­ç»ƒ
python train.py
```

## ğŸ“Š é¢„æœŸè®­ç»ƒæ—¶é—´

åŸºäº10000æ¡æ ·æœ¬çš„é¢„æœŸè®­ç»ƒæ—¶é—´ï¼š

| ç¡¬ä»¶ | é¢„è®¡æ—¶é—´ |
|------|---------|
| GPU (NVIDIA RTX 3060+) | 5-10åˆ†é’Ÿ |
| CPU (8æ ¸+) | 20-30åˆ†é’Ÿ |
| CPU (4æ ¸) | 40-60åˆ†é’Ÿ |

## ğŸ“ˆ é¢„æœŸæ€§èƒ½

åŸºäº10000æ¡å‡è¡¡æ ·æœ¬è®­ç»ƒï¼š

| æŒ‡æ ‡ | é¢„æœŸèŒƒå›´ |
|------|---------|
| è®­ç»ƒé›†å‡†ç¡®ç‡ | 85-92% |
| éªŒè¯é›†å‡†ç¡®ç‡ | 80-87% |
| æµ‹è¯•é›†å‡†ç¡®ç‡ | 80-87% |
| F1 Score | 0.80-0.87 |

## ğŸ” è®­ç»ƒè¾“å‡ºç¤ºä¾‹

```bash
$ python train.py

============================================================
TextCNN Sentiment Classification Training
============================================================

ğŸ“± Device: cuda

ğŸ“‚ Loading data...
Loading data from ../bert-sentential-classifer/train.csv...
  Loaded 3600000 samples

âš–ï¸  Balanced sampling 10000 training samples...
   âœ… Sampled 5000 negative + 5000 positive = 10000 total

Building vocabulary...
  Total unique words: 45678
  Vocabulary size: 30245 (min_freq=2)

============================================================
Dataset Statistics:
  Train: 10000 samples (neg: 5000, pos: 5000)
  Dev:   1001 samples (neg: 511, pos: 490)
  Test:  1001 samples (neg: 494, pos: 507)
  Vocabulary size: 30245
  Max sequence length: 256
============================================================

ğŸ”¨ Creating model...
âœ“ Initialized random embeddings
âœ“ TextCNN initialized:
    Vocab size: 30245
    Embedding dim: 300
    Filter sizes: [3, 4, 5]
    Num filters per size: 100
    Total feature dim: 300
    Dropout: 0.5

============================================================
Model Summary:
  Total parameters: 9,373,802
  Trainable parameters: 9,373,802
============================================================

ğŸ‹ï¸  Training Started
============================================================

Epoch 1/15: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:12<00:00, 12.58it/s, loss=0.4532]

ğŸ“Š Evaluating on dev set...

============================================================
Epoch 1/15 Results:
  Train | Loss: 0.5234 | Acc: 0.7456 | F1: 0.7398
  Dev   | Loss: 0.4123 | Acc: 0.8023 | F1: 0.7998
        | Precision: 0.8134 | Recall: 0.7865

  Dev Confusion Matrix:
    [[TN=413, FP=98],
     [FN=100, TP=390]]
============================================================

ğŸ’¾ Best model saved! (F1: 0.7998)

... (ç»§ç»­è®­ç»ƒ) ...

============================================================
Epoch 15/15 Results:
  Train | Loss: 0.2134 | Acc: 0.9156 | F1: 0.9145
  Dev   | Loss: 0.3521 | Acc: 0.8512 | F1: 0.8489
        | Precision: 0.8623 | Recall: 0.8357
============================================================

ğŸ§ª Evaluating on Test Set
============================================================

ğŸ“Š Test Set Results:
  Loss: 0.3498
  Accuracy: 0.8501
  F1 Score: 0.8478
  Precision: 0.8612
  Recall: 0.8346

  Test Confusion Matrix:
    [[TN=423, FP=71],
     [FN=79, TP=428]]

============================================================
âœ… Training Completed!
ğŸ“Š Best Dev F1: 0.8489
ğŸ“Š Test F1: 0.8478
ğŸ’¾ Model saved to: ./outputs/textcnn_model.pth
============================================================
```

## ğŸ“ è®­ç»ƒè¾“å‡ºæ–‡ä»¶

è®­ç»ƒå®Œæˆåä¼šç”Ÿæˆï¼š

```
textcnn-sentiment-classifier/
â””â”€â”€ outputs/
    â”œâ”€â”€ textcnn_model.pth         # è®­ç»ƒå¥½çš„æ¨¡å‹ (æœ€ä½³)
    â”œâ”€â”€ vocab.pkl                 # è¯è¡¨
    â”œâ”€â”€ training_curves.png       # è®­ç»ƒæ›²çº¿å›¾
    â””â”€â”€ test_results.json         # æµ‹è¯•ç»“æœ

â””â”€â”€ logs/
    â””â”€â”€ training_history.json     # å®Œæ•´è®­ç»ƒå†å²
```

## ğŸ¯ ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹

```bash
# äº¤äº’å¼é¢„æµ‹
python predict.py
```

```python
# Python API
from predict import SentimentPredictor

predictor = SentimentPredictor(
    model_path="outputs/textcnn_model.pth",
    vocab_path="outputs/vocab.pkl"
)

text = "This product is amazing! I love it."
pred, confidence = predictor.predict(text)
print(f"Prediction: {predictor.label_names[pred]} ({confidence:.2%})")
# è¾“å‡º: Prediction: æ­£é¢ (Positive) (92.34%)
```

## ğŸ”§ å¦‚éœ€è°ƒæ•´é…ç½®

ç¼–è¾‘ `config.py` æ–‡ä»¶ï¼š

```python
# ä½¿ç”¨æ›´å¤šè®­ç»ƒæ•°æ®
MAX_TRAIN_SAMPLES = 50000    # 5ä¸‡æ¡

# ä½¿ç”¨å…¨éƒ¨æ•°æ®
MAX_TRAIN_SAMPLES = None     # å…¨éƒ¨ (~360ä¸‡æ¡)

# ä¸å‡è¡¡é‡‡æ ·ï¼ˆéšæœºé‡‡æ ·ï¼‰
BALANCE_TRAIN_DATA = False

# è°ƒæ•´è®­ç»ƒè½®æ•°
NUM_EPOCHS = 10              # å‡å°‘åˆ°10è½®
NUM_EPOCHS = 20              # å¢åŠ åˆ°20è½®

# è°ƒæ•´æ‰¹æ¬¡å¤§å°
BATCH_SIZE = 32              # å‡å° (æ˜¾å­˜ä¸è¶³æ—¶)
BATCH_SIZE = 128             # å¢å¤§ (åŠ å¿«è®­ç»ƒ)
```

## âœ… é…ç½®éªŒè¯

è¿è¡Œæµ‹è¯•è„šæœ¬éªŒè¯é…ç½®ï¼š

```bash
python test_config.py
```

è¾“å‡ºç¤ºä¾‹ï¼š
```
============================================================
TextCNN é…ç½®æµ‹è¯•
============================================================

ğŸ“‹ å½“å‰é…ç½®:
  MAX_TRAIN_SAMPLES: 10000
  BALANCE_TRAIN_DATA: True
  BATCH_SIZE: 64
  NUM_EPOCHS: 15
  EMBEDDING_DIM: 300
  NUM_FILTERS: 100
  FILTER_SIZES: [3, 4, 5]
  MAX_SEQ_LENGTH: 256

============================================================
æµ‹è¯•æ•°æ®åŠ è½½...
============================================================

âš–ï¸  Balanced sampling 10000 training samples...
   âœ… Sampled 5000 negative + 5000 positive = 10000 total

âœ… æ•°æ®åŠ è½½æˆåŠŸï¼

ğŸ“Š æ•°æ®é›†ä¿¡æ¯:
  è®­ç»ƒé›†: 10000 æ ·æœ¬
  éªŒè¯é›†: 1001 æ ·æœ¬
  æµ‹è¯•é›†: 1001 æ ·æœ¬
  è¯è¡¨å¤§å°: 30245

âš–ï¸  è®­ç»ƒé›†æ ‡ç­¾åˆ†å¸ƒ:
  è´Ÿé¢ (0): 5000 (50.0%)
  æ­£é¢ (1): 5000 (50.0%)
  âœ… æ ·æœ¬åˆ†å¸ƒå‡è¡¡ï¼

============================================================
æµ‹è¯•å®Œæˆï¼å‡†å¤‡å¼€å§‹è®­ç»ƒã€‚
============================================================

è¿è¡Œä»¥ä¸‹å‘½ä»¤å¼€å§‹è®­ç»ƒ:
  python train.py
```

## ğŸ“ æ€»ç»“

å·²å®Œæˆä»¥ä¸‹é…ç½®ä¿®æ”¹ï¼š

- âœ… è®­ç»ƒæ ·æœ¬æ•°: 10,000æ¡ (å‡è¡¡é‡‡æ ·)
- âœ… æ­£è´Ÿæ ·æœ¬åˆ†å¸ƒ: 5,000:5,000 (50%:50%)
- âœ… è®­ç»ƒè½®æ•°: 15è½®
- âœ… å…¶ä»–å‚æ•°ä¿æŒé»˜è®¤

**ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒäº†ï¼**

```bash
cd textcnn-sentiment-classifier
python train.py
```

é¢„è®¡è®­ç»ƒæ—¶é—´: **5-30åˆ†é’Ÿ** (å–å†³äºç¡¬ä»¶)

