# TextCNN æƒ…æ„Ÿåˆ†ç±» - å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸ¯ ç›®æ ‡

ä½¿ç”¨ TextCNN æ¨¡å‹å¯¹äº§å“è¯„è®ºè¿›è¡Œæƒ…æ„Ÿåˆ†æï¼Œå°†è¯„è®ºåˆ†ä¸º"æ­£é¢"å’Œ"è´Ÿé¢"ã€‚

## ğŸš€ 5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹

### æ–¹å¼1ï¼šä½¿ç”¨è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd textcnn-sentiment-classifier

# å®‰è£…ä¾èµ–
./setup.sh
# æˆ–è€…æ‰‹åŠ¨å®‰è£…
pip install torch numpy scikit-learn matplotlib tqdm

# å¼€å§‹è®­ç»ƒ
python train.py

# äº¤äº’å¼é¢„æµ‹
python predict.py
```

### æ–¹å¼2ï¼šä¸€é”®è¿è¡Œ

```bash
cd textcnn-sentiment-classifier
./setup.sh  # å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
./run.sh    # è®­ç»ƒ + æµ‹è¯•
```

## ğŸ“ æ•°æ®æ ¼å¼

é¡¹ç›®ä¼šè‡ªåŠ¨ä»çˆ¶ç›®å½•è¯»å–æ•°æ®ï¼š
```
../bert-sentential-classifer/
â”œâ”€â”€ train.csv  # è®­ç»ƒæ•°æ®
â”œâ”€â”€ dev.csv    # éªŒè¯æ•°æ®
â””â”€â”€ test.csv   # æµ‹è¯•æ•°æ®
```

CSVæ ¼å¼ï¼š`label,title,text`
- label: 1=è´Ÿé¢ï¼Œ2=æ­£é¢
- title: è¯„è®ºæ ‡é¢˜
- text: è¯„è®ºå†…å®¹

## ğŸ“Š æ¨¡å‹é…ç½®

åœ¨ `config.py` ä¸­å¯ä»¥è°ƒæ•´å‚æ•°ï¼š

**å¿«é€Ÿå®éªŒï¼ˆå°æ•°æ®é›†ï¼Œå¿«é€Ÿè®­ç»ƒï¼‰ï¼š**
```python
MAX_TRAIN_SAMPLES = 5000    # é™åˆ¶è®­ç»ƒæ ·æœ¬æ•°
BATCH_SIZE = 64
NUM_EPOCHS = 5
MAX_SEQ_LENGTH = 128
```

**å®Œæ•´è®­ç»ƒï¼ˆå¤§æ•°æ®é›†ï¼Œæ›´å¥½æ•ˆæœï¼‰ï¼š**
```python
MAX_TRAIN_SAMPLES = None    # ä½¿ç”¨å…¨éƒ¨æ•°æ®
BATCH_SIZE = 64
NUM_EPOCHS = 10
MAX_SEQ_LENGTH = 256
```

## ğŸ—ï¸ TextCNN æ¶æ„è¯´æ˜

```
è¾“å…¥æ–‡æœ¬: "This product is great!"
    â†“
åˆ†è¯ & æ¸…æ´—: ["this", "product", "is", "great"]
    â†“
Embedding: [[0.2, -0.1, ...], [0.5, 0.3, ...], ...]
    â†“
å·ç§¯å±‚ï¼ˆå¤šä¸ªçª—å£å¤§å°ï¼‰:
  - 3-gramå·ç§¯: "this product is", "product is great"
  - 4-gramå·ç§¯: "this product is great"
  - 5-gramå·ç§¯: (padding needed)
    â†“
Max Pooling: æå–æœ€é‡è¦çš„ç‰¹å¾
    â†“
å…¨è¿æ¥å±‚: åˆ†ç±»
    â†“
è¾“å‡º: [0.1, 0.9] â†’ æ­£é¢ (90% ç½®ä¿¡åº¦)
```

**å…³é”®å‚æ•°ï¼š**
- `FILTER_SIZES = [3, 4, 5]`: çª—å£å¤§å°ï¼ˆæ•è·3/4/5ä¸ªè¯çš„æ¨¡å¼ï¼‰
- `NUM_FILTERS = 100`: æ¯ä¸ªçª—å£å¤§å°çš„å·ç§¯æ ¸æ•°é‡
- `EMBEDDING_DIM = 300`: è¯å‘é‡ç»´åº¦

## ğŸ“ˆ è®­ç»ƒè¿‡ç¨‹

è®­ç»ƒè„šæœ¬ä¼šè¾“å‡ºï¼š

```
============================================================
TextCNN Sentiment Classification Training
============================================================

ğŸ“± Device: cuda

ğŸ“‚ Loading data...
Loading data from ../bert-sentential-classifer/train.csv...
  Loaded 3600000 samples

Building vocabulary...
  Total unique words: 234567
  Vocabulary size: 50000 (min_freq=2)

============================================================
Dataset Statistics:
  Train: 10000 samples (neg: 5000, pos: 5000)
  Dev:   1001 samples (neg: 511, pos: 490)
  Test:  1001 samples (neg: 494, pos: 507)
  Vocabulary size: 50000
  Max sequence length: 256
============================================================

ğŸ”¨ Creating model...
âœ“ Initialized random embeddings
âœ“ TextCNN initialized:
    Vocab size: 50000
    Embedding dim: 300
    Filter sizes: [3, 4, 5]
    Num filters per size: 100
    Total feature dim: 300
    Dropout: 0.5

============================================================
Model Summary:
  Total parameters: 15,300,302
  Trainable parameters: 15,300,302
============================================================

============================================================
ğŸ‹ï¸  Training Started
============================================================

Epoch 1/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:15<00:00, 10.12it/s, loss=0.4532]

ğŸ“Š Evaluating on dev set...

============================================================
Epoch 1/10 Results:
  Train | Loss: 0.5234 | Acc: 0.7456 | F1: 0.7398
  Dev   | Loss: 0.4123 | Acc: 0.8123 | F1: 0.8098
        | Precision: 0.8234 | Recall: 0.7965

  Dev Confusion Matrix:
    [[TN=420, FP=91],
     [FN=97, TP=393]]
============================================================

ğŸ’¾ Best model saved! (F1: 0.8098)

... (ç»§ç»­è®­ç»ƒ) ...

============================================================
âœ… Training Completed!
ğŸ“Š Best Dev F1: 0.8567
ğŸ“Š Test F1: 0.8501
ğŸ’¾ Model saved to: ./outputs/textcnn_model.pth
============================================================
```

## ğŸ® ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹

### Python API

```python
from predict import SentimentPredictor

# åˆå§‹åŒ–
predictor = SentimentPredictor(
    model_path="outputs/textcnn_model.pth",
    vocab_path="outputs/vocab.pkl"
)

# é¢„æµ‹
text = "This product is amazing!"
pred, confidence = predictor.predict(text)
print(f"{predictor.label_names[pred]} ({confidence:.2%})")
# è¾“å‡º: æ­£é¢ (Positive) (95.23%)
```

### å‘½ä»¤è¡Œäº¤äº’

```bash
python predict.py
```

```
============================================================
TextCNN Sentiment Analysis - Interactive Demo
============================================================

ğŸ“ Example Predictions:
1. Text: "This product is amazing! I love it so much."
   Prediction: æ­£é¢ (Positive)
   Confidence: 0.9523
   Probabilities: [Neg: 0.0477, Pos: 0.9523]

...

ğŸ® Interactive Mode
============================================================

Enter review text: I hate this product, it broke immediately.

  ğŸ“Š Prediction: è´Ÿé¢ (Negative)
  ğŸ“ˆ Confidence: 0.8765
  ğŸ“‰ Probabilities: [Neg: 0.8765, Pos: 0.1235]
```

## ğŸ“‚ è¾“å‡ºæ–‡ä»¶

è®­ç»ƒå®Œæˆåä¼šç”Ÿæˆï¼š

```
outputs/
â”œâ”€â”€ textcnn_model.pth         # æ¨¡å‹æƒé‡ï¼ˆæœ€ä½³ï¼‰
â”œâ”€â”€ vocab.pkl                 # è¯è¡¨
â”œâ”€â”€ training_curves.png       # è®­ç»ƒæ›²çº¿ï¼ˆLoss/Acc/F1ï¼‰
â””â”€â”€ test_results.json         # æµ‹è¯•é›†ç»“æœ

logs/
â””â”€â”€ training_history.json     # å®Œæ•´è®­ç»ƒå†å²
```

## âš™ï¸ æ€§èƒ½è°ƒä¼˜

### æé«˜å‡†ç¡®ç‡

1. **å¢åŠ è®­ç»ƒæ•°æ®**
   ```python
   MAX_TRAIN_SAMPLES = None  # ä½¿ç”¨å…¨éƒ¨æ•°æ®
   ```

2. **è°ƒæ•´æ¨¡å‹å®¹é‡**
   ```python
   NUM_FILTERS = 200         # å¢åŠ å·ç§¯æ ¸æ•°é‡
   FILTER_SIZES = [2,3,4,5]  # å¢åŠ çª—å£å¤§å°ç§ç±»
   EMBEDDING_DIM = 512       # å¢åŠ è¯å‘é‡ç»´åº¦
   ```

3. **é™ä½æ­£åˆ™åŒ–**
   ```python
   DROPOUT_RATE = 0.3        # é™ä½dropout
   WEIGHT_DECAY = 1e-5       # é™ä½æƒé‡è¡°å‡
   ```

### åŠ å¿«è®­ç»ƒé€Ÿåº¦

1. **å‡å°‘æ•°æ®**
   ```python
   MAX_TRAIN_SAMPLES = 5000  # é™åˆ¶æ ·æœ¬æ•°
   ```

2. **å‡å°åºåˆ—é•¿åº¦**
   ```python
   MAX_SEQ_LENGTH = 128      # é™ä½æœ€å¤§é•¿åº¦
   ```

3. **å¢å¤§æ‰¹æ¬¡**
   ```python
   BATCH_SIZE = 128          # å¢å¤§batch size
   ```

## ğŸ› æ•…éšœæ’é™¤

### CUDA å†…å­˜ä¸è¶³

```python
# åœ¨ config.py ä¸­ä¿®æ”¹
BATCH_SIZE = 32           # å‡å°æ‰¹æ¬¡
MAX_SEQ_LENGTH = 128      # å‡å°åºåˆ—é•¿åº¦
NUM_FILTERS = 50          # å‡å°å·ç§¯æ ¸æ•°é‡
DEVICE = "cpu"            # æˆ–ä½¿ç”¨CPU
```

### ä¾èµ–åŒ…é—®é¢˜

```bash
# å®‰è£…ç‰¹å®šç‰ˆæœ¬
pip install torch==1.10.0 --index-url https://download.pytorch.org/whl/cpu

# æˆ–ä½¿ç”¨conda
conda install pytorch torchvision torchaudio cpuonly -c pytorch
```

### æ•°æ®æ–‡ä»¶æ‰¾ä¸åˆ°

ç¡®ä¿æ•°æ®æ–‡ä»¶åœ¨æ­£ç¡®ä½ç½®ï¼š
```
exp02-sentiment-classificationn/
â”œâ”€â”€ bert-sentential-classifer/
â”‚   â”œâ”€â”€ train.csv  â† æ•°æ®æ–‡ä»¶
â”‚   â”œâ”€â”€ dev.csv
â”‚   â””â”€â”€ test.csv
â””â”€â”€ textcnn-sentiment-classifier/  â† å½“å‰ç›®å½•
    â””â”€â”€ ...
```

## ğŸ“Š æ€§èƒ½åŸºå‡†

åœ¨ Amazon äº§å“è¯„è®ºæ•°æ®é›†ä¸Šçš„å…¸å‹æ€§èƒ½ï¼š

| é…ç½® | è®­ç»ƒæ ·æœ¬ | è®­ç»ƒæ—¶é—´ | Dev Acc | Test Acc | Test F1 |
|------|----------|----------|---------|----------|---------|
| å°å‹ | 5K | ~2åˆ†é’Ÿ | 82.3% | 81.5% | 0.81 |
| ä¸­å‹ | 50K | ~15åˆ†é’Ÿ | 86.7% | 86.2% | 0.86 |
| å¤§å‹ | 500K | ~2å°æ—¶ | 89.5% | 89.1% | 0.89 |

*æµ‹è¯•ç¯å¢ƒ: NVIDIA RTX 3060, BATCH_SIZE=64*

## ğŸ“ å…³é”®æ¦‚å¿µ

### 1. å·ç§¯æ ¸ï¼ˆFilterï¼‰
- å¤§å°ï¼ˆå¦‚3ï¼‰è¡¨ç¤ºä¸€æ¬¡çœ‹å‡ ä¸ªè¯
- æ•°é‡ï¼ˆå¦‚100ï¼‰è¡¨ç¤ºå­¦ä¹ å¤šå°‘ç§æ¨¡å¼

### 2. Pooling
- Max Pooling: ä»æ•´ä¸ªå¥å­ä¸­æå–æœ€é‡è¦çš„ç‰¹å¾
- ä¸ä¾èµ–å¥å­é•¿åº¦

### 3. Dropout
- è®­ç»ƒæ—¶éšæœºä¸¢å¼ƒä¸€äº›ç¥ç»å…ƒ
- é˜²æ­¢è¿‡æ‹Ÿåˆ

### 4. Early Stopping
- éªŒè¯é›†æ€§èƒ½ä¸å†æå‡æ—¶åœæ­¢è®­ç»ƒ
- é˜²æ­¢è¿‡æ‹Ÿåˆ

## ğŸ“š å‚è€ƒèµ„æ–™

- **åŸè®ºæ–‡**: [Convolutional Neural Networks for Sentence Classification](https://arxiv.org/abs/1408.5882) (Kim, 2014)
- **PyTorch æ–‡æ¡£**: https://pytorch.org/docs/
- **TextCNN è¯¦è§£**: [Understanding Convolutional Neural Networks for NLP](http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/)

## ğŸ’¡ æç¤º

1. **é¦–æ¬¡è¿è¡Œ**: ä½¿ç”¨å°æ•°æ®é›†ï¼ˆ`MAX_TRAIN_SAMPLES=5000`ï¼‰å¿«é€ŸéªŒè¯
2. **æ­£å¼å®éªŒ**: ä½¿ç”¨å…¨éƒ¨æ•°æ®ï¼ˆ`MAX_TRAIN_SAMPLES=None`ï¼‰
3. **å¯¹æ¯”å®éªŒ**: å°è¯•ä¸åŒçš„ `FILTER_SIZES` å’Œ `NUM_FILTERS`
4. **ä¿å­˜ç»“æœ**: è®­ç»ƒæ›²çº¿å’ŒæŒ‡æ ‡ä¼šè‡ªåŠ¨ä¿å­˜

---

**å‡†å¤‡å¥½äº†ï¼Ÿå¼€å§‹è®­ç»ƒï¼** ğŸš€

```bash
python train.py
```

