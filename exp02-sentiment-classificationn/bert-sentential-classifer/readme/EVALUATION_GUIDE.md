# BERTæƒ…æ„Ÿåˆ†ç±» - å®Œæ•´è¯„ä¼°æŒ‡å—

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•ä½¿ç”¨æ–°å¢çš„è¯„ä¼°è„šæœ¬è¿›è¡Œå…¨é¢çš„æ¨¡å‹è¯„ä¼°å’Œå¯¹æ¯”å®éªŒã€‚

## ğŸ“‹ æ–°å¢è¯„ä¼°åŠŸèƒ½

### âœ… å·²å®ç°çš„è¯„ä¼°æŒ‡æ ‡

1. **ç»¼åˆè¯„ä¼°æŒ‡æ ‡**
   - âœ… å‡†ç¡®ç‡ (Accuracy)
   - âœ… ç²¾ç¡®ç‡ (Precision)
   - âœ… å¬å›ç‡ (Recall)
   - âœ… F1åˆ†æ•° (F1-score)
   - âœ… AUC-ROC
   - âœ… æ··æ·†çŸ©é˜µå¯è§†åŒ–
   - âœ… ROCæ›²çº¿

2. **é²æ£’æ€§æµ‹è¯•**
   - âœ… KæŠ˜äº¤å‰éªŒè¯

3. **å¯¹æ¯”å®éªŒ**
   - âœ… ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆSVMã€æœ´ç´ è´å¶æ–¯ã€é€»è¾‘å›å½’ã€éšæœºæ£®æ—ï¼‰
   - âœ… BERT vs ä¼ ç»Ÿæ¨¡å‹æ€§èƒ½å¯¹æ¯”

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å‰ææ¡ä»¶

ç¡®ä¿å·²è®­ç»ƒå¥½BERTæ¨¡å‹ï¼š
```bash
python main.py
```

### è¿è¡Œå®Œæ•´è¯„ä¼°å¥—ä»¶

```bash
bash run_complete_evaluation.sh
```

è¿™å°†ä¾æ¬¡è¿è¡Œæ‰€æœ‰è¯„ä¼°å®éªŒå¹¶ç”Ÿæˆå®Œæ•´æŠ¥å‘Šã€‚

## ğŸ“ å•ç‹¬è¿è¡Œå„ä¸ªè¯„ä¼°

### 1. ç»¼åˆè¯„ä¼°ï¼ˆæ¨èé¦–å…ˆè¿è¡Œï¼‰

```bash
python comprehensive_evaluation.py --test-samples 1000 --output-dir evaluation_results
```

**å‚æ•°è¯´æ˜ï¼š**
- `--test-samples`: æµ‹è¯•æ ·æœ¬æ•°é‡ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨éƒ¨ï¼‰
- `--output-dir`: è¾“å‡ºç›®å½•

**ç”Ÿæˆæ–‡ä»¶ï¼š**
- `confusion_matrix.png` - æ··æ·†çŸ©é˜µå¯è§†åŒ–
- `roc_curve.png` - ROCæ›²çº¿
- `evaluation_report.txt` - è¯¦ç»†è¯„ä¼°æŠ¥å‘Š

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
å‡†ç¡®ç‡ (Accuracy):   0.8542
ç²¾ç¡®ç‡ (Precision):  0.8621
å¬å›ç‡ (Recall):     0.8453
F1åˆ†æ•° (F1-score):   0.8536
AUC-ROC:             0.9234
```

### 2. KæŠ˜äº¤å‰éªŒè¯

```bash
python cross_validation.py --n-folds 5 --max-samples 5000 --output-dir evaluation_results
```

**å‚æ•°è¯´æ˜ï¼š**
- `--n-folds`: KæŠ˜äº¤å‰éªŒè¯çš„æŠ˜æ•°ï¼ˆé»˜è®¤5ï¼‰
- `--max-samples`: æœ€å¤§æ ·æœ¬æ•°ï¼ˆå‡å°‘è®­ç»ƒæ—¶é—´ï¼‰
- `--output-dir`: è¾“å‡ºç›®å½•

**ç”Ÿæˆæ–‡ä»¶ï¼š**
- `cross_validation_results.csv` - å„æŠ˜è¯¦ç»†ç»“æœ
- `cross_validation_results.png` - ç»“æœå¯è§†åŒ–å›¾è¡¨
- `cross_validation_report.txt` - äº¤å‰éªŒè¯æŠ¥å‘Š

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
å¹³å‡æŒ‡æ ‡ (Â± æ ‡å‡†å·®):
  å‡†ç¡®ç‡:  0.8512 Â± 0.0123
  ç²¾ç¡®ç‡:  0.8598 Â± 0.0145
  å¬å›ç‡:  0.8431 Â± 0.0167
  F1åˆ†æ•°:  0.8513 Â± 0.0134
```

### 3. ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹

```bash
python traditional_models.py --max-train-samples 10000 --save-models --output-dir evaluation_results
```

**å‚æ•°è¯´æ˜ï¼š**
- `--max-features`: TF-IDFç‰¹å¾æœ€å¤§æ•°é‡ï¼ˆé»˜è®¤5000ï¼‰
- `--max-train-samples`: è®­ç»ƒæ ·æœ¬æ•°é‡é™åˆ¶
- `--save-models`: ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹
- `--output-dir`: è¾“å‡ºç›®å½•

**åŒ…å«çš„æ¨¡å‹ï¼š**
- é€»è¾‘å›å½’ (Logistic Regression)
- æ”¯æŒå‘é‡æœº (SVM - Linear Kernel)
- æœ´ç´ è´å¶æ–¯ (Naive Bayes)
- éšæœºæ£®æ— (Random Forest)

**ç”Ÿæˆæ–‡ä»¶ï¼š**
- `traditional_models_results.csv` - ç»“æœæ•°æ®
- `traditional_models_report.txt` - è¯¦ç»†æŠ¥å‘Š
- `traditional_models/` - ä¿å­˜çš„æ¨¡å‹æ–‡ä»¶ï¼ˆå¦‚æœä½¿ç”¨ --save-modelsï¼‰

### 4. BERT vs ä¼ ç»Ÿæ¨¡å‹å¯¹æ¯”

```bash
python model_comparison.py --max-train-samples 10000 --output-dir evaluation_results
```

**å‚æ•°è¯´æ˜ï¼š**
- `--max-train-samples`: è®­ç»ƒæ ·æœ¬æ•°é‡
- `--max-test-samples`: æµ‹è¯•æ ·æœ¬æ•°é‡ï¼ˆå¯é€‰ï¼‰
- `--output-dir`: è¾“å‡ºç›®å½•

**ç”Ÿæˆæ–‡ä»¶ï¼š**
- `model_comparison.png` - æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”å›¾
- `time_comparison.png` - æ—¶é—´æ•ˆç‡å¯¹æ¯”å›¾
- `model_comparison_report.txt` - è¯¦ç»†å¯¹æ¯”æŠ¥å‘Š
- `model_comparison_results.csv` - å¯¹æ¯”æ•°æ®

## ğŸ“Š è¾“å‡ºæ–‡ä»¶è¯´æ˜

æ‰€æœ‰è¯„ä¼°ç»“æœé»˜è®¤ä¿å­˜åœ¨ `evaluation_results/` ç›®å½•ä¸‹ï¼š

```
evaluation_results/
â”œâ”€â”€ confusion_matrix.png              # æ··æ·†çŸ©é˜µ
â”œâ”€â”€ roc_curve.png                     # ROCæ›²çº¿
â”œâ”€â”€ evaluation_report.txt             # BERTç»¼åˆè¯„ä¼°æŠ¥å‘Š
â”œâ”€â”€ cross_validation_results.csv      # äº¤å‰éªŒè¯æ•°æ®
â”œâ”€â”€ cross_validation_results.png      # äº¤å‰éªŒè¯å¯è§†åŒ–
â”œâ”€â”€ cross_validation_report.txt       # äº¤å‰éªŒè¯æŠ¥å‘Š
â”œâ”€â”€ traditional_models_results.csv    # ä¼ ç»Ÿæ¨¡å‹ç»“æœ
â”œâ”€â”€ traditional_models_report.txt     # ä¼ ç»Ÿæ¨¡å‹æŠ¥å‘Š
â”œâ”€â”€ model_comparison.png              # æ¨¡å‹å¯¹æ¯”å›¾
â”œâ”€â”€ time_comparison.png               # æ—¶é—´å¯¹æ¯”å›¾
â”œâ”€â”€ model_comparison_report.txt       # æ¨¡å‹å¯¹æ¯”æŠ¥å‘Š
â”œâ”€â”€ model_comparison_results.csv      # æ¨¡å‹å¯¹æ¯”æ•°æ®
â””â”€â”€ traditional_models/               # ä¿å­˜çš„ä¼ ç»Ÿæ¨¡å‹
    â”œâ”€â”€ vectorizer.pkl
    â”œâ”€â”€ logistic_regression.pkl
    â”œâ”€â”€ svm_linear.pkl
    â”œâ”€â”€ naive_bayes.pkl
    â””â”€â”€ random_forest.pkl
```

## ğŸ¯ è¯„ä¼°æŒ‡æ ‡è¯´æ˜

### å‡†ç¡®ç‡ (Accuracy)
æ­£ç¡®é¢„æµ‹çš„æ ·æœ¬å æ€»æ ·æœ¬çš„æ¯”ä¾‹ã€‚é€‚ç”¨äºç±»åˆ«å¹³è¡¡çš„æ•°æ®é›†ã€‚

### ç²¾ç¡®ç‡ (Precision)
é¢„æµ‹ä¸ºæ­£ç±»ä¸­çœŸæ­£ä¸ºæ­£ç±»çš„æ¯”ä¾‹ã€‚è¡¡é‡æ¨¡å‹çš„"ç²¾å‡†åº¦"ã€‚

### å¬å›ç‡ (Recall)
çœŸæ­£çš„æ­£ç±»ä¸­è¢«æ­£ç¡®é¢„æµ‹çš„æ¯”ä¾‹ã€‚è¡¡é‡æ¨¡å‹çš„"å…¨é¢æ€§"ã€‚

### F1åˆ†æ•° (F1-score)
ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡æ•°ã€‚ç»¼åˆè€ƒè™‘ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„æŒ‡æ ‡ã€‚

### AUC-ROC
ROCæ›²çº¿ä¸‹çš„é¢ç§¯ï¼Œè¡¡é‡æ¨¡å‹åŒºåˆ†æ­£è´Ÿç±»çš„èƒ½åŠ›ã€‚å€¼è¶Šæ¥è¿‘1è¡¨ç¤ºæ€§èƒ½è¶Šå¥½ã€‚

### æ··æ·†çŸ©é˜µ
- **çœŸé˜´æ€§ (TN)**: æ­£ç¡®é¢„æµ‹ä¸ºè´Ÿç±»çš„æ•°é‡
- **å‡é˜³æ€§ (FP)**: é”™è¯¯é¢„æµ‹ä¸ºæ­£ç±»çš„æ•°é‡ï¼ˆç¬¬ä¸€ç±»é”™è¯¯ï¼‰
- **å‡é˜´æ€§ (FN)**: é”™è¯¯é¢„æµ‹ä¸ºè´Ÿç±»çš„æ•°é‡ï¼ˆç¬¬äºŒç±»é”™è¯¯ï¼‰
- **çœŸé˜³æ€§ (TP)**: æ­£ç¡®é¢„æµ‹ä¸ºæ­£ç±»çš„æ•°é‡

## ğŸ’¡ ä½¿ç”¨å»ºè®®

### 1. åŸºç¡€è¯„ä¼°æµç¨‹
```bash
# æ­¥éª¤1ï¼šè®­ç»ƒBERTæ¨¡å‹
python main.py

# æ­¥éª¤2ï¼šç»¼åˆè¯„ä¼°
python comprehensive_evaluation.py

# æ­¥éª¤3ï¼šæŸ¥çœ‹ç»“æœ
cat evaluation_results/evaluation_report.txt
```

### 2. é²æ£’æ€§æµ‹è¯•
å¦‚æœéœ€è¦éªŒè¯æ¨¡å‹çš„ç¨³å®šæ€§å’Œæ³›åŒ–èƒ½åŠ›ï¼š
```bash
python cross_validation.py --n-folds 5
```

### 3. æ¨¡å‹å¯¹æ¯”
å¦‚æœéœ€è¦ä¸ä¼ ç»Ÿæ–¹æ³•å¯¹æ¯”BERTçš„ä¼˜åŠ¿ï¼š
```bash
# å…ˆè®­ç»ƒä¼ ç»Ÿæ¨¡å‹
python traditional_models.py --save-models

# å†è¿è¡Œå¯¹æ¯”å®éªŒ
python model_comparison.py
```

### 4. å®Œæ•´è¯„ä¼°
å¦‚æœéœ€è¦ç”Ÿæˆå®Œæ•´çš„è¯„ä¼°æŠ¥å‘Šï¼š
```bash
bash run_complete_evaluation.sh
```

## âš™ï¸ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### å‡å°‘è¯„ä¼°æ—¶é—´
```bash
# é™åˆ¶æµ‹è¯•æ ·æœ¬æ•°é‡
python comprehensive_evaluation.py --test-samples 1000

# é™åˆ¶äº¤å‰éªŒè¯æ ·æœ¬æ•°é‡
python cross_validation.py --max-samples 3000

# é™åˆ¶ä¼ ç»Ÿæ¨¡å‹è®­ç»ƒæ ·æœ¬
python traditional_models.py --max-train-samples 5000
```

### GPUåŠ é€Ÿ
å¦‚æœæœ‰GPUï¼ŒBERTè¯„ä¼°ä¼šè‡ªåŠ¨ä½¿ç”¨GPUåŠ é€Ÿã€‚ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹ä¸»è¦ä½¿ç”¨CPUã€‚

## ğŸ“ˆ é¢„æœŸç»“æœ

### BERTæ¨¡å‹å…¸å‹æ€§èƒ½
- å‡†ç¡®ç‡: 85-90%
- F1åˆ†æ•°: 84-89%
- AUC-ROC: 90-95%

### ä¼ ç»Ÿæ¨¡å‹å…¸å‹æ€§èƒ½
- SVM: F1 ~75-82%
- é€»è¾‘å›å½’: F1 ~73-80%
- æœ´ç´ è´å¶æ–¯: F1 ~70-78%
- éšæœºæ£®æ—: F1 ~72-79%

### æ€§èƒ½å·®è·
BERTç›¸æ¯”æœ€ä½³ä¼ ç»Ÿæ¨¡å‹é€šå¸¸æœ‰5-10%çš„F1åˆ†æ•°æå‡ã€‚

## ğŸ”§ æ•…éšœæ’é™¤

### 1. æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°
```
é”™è¯¯: æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°: best_epoch_model.pth
è§£å†³: å…ˆè¿è¡Œ python main.py è®­ç»ƒæ¨¡å‹
```

### 2. å†…å­˜ä¸è¶³
```
è§£å†³: å‡å°‘æ ·æœ¬æ•°é‡
python comprehensive_evaluation.py --test-samples 500
```

### 3. è®­ç»ƒæ—¶é—´è¿‡é•¿
```
è§£å†³: ä½¿ç”¨è¾ƒå°çš„æ ·æœ¬é›†è¿›è¡Œäº¤å‰éªŒè¯
python cross_validation.py --max-samples 2000
```

## ğŸ“š å‚è€ƒèµ„æ–™

- [sklearnè¯„ä¼°æŒ‡æ ‡æ–‡æ¡£](https://scikit-learn.org/stable/modules/model_evaluation.html)
- [BERTè®ºæ–‡](https://arxiv.org/abs/1810.04805)
- [ROC-AUCè§£é‡Š](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)

## âœ¨ æ€»ç»“

æœ¬è¯„ä¼°å¥—ä»¶æä¾›äº†å…¨é¢çš„æ¨¡å‹è¯„ä¼°å·¥å…·ï¼ŒåŒ…æ‹¬ï¼š
- âœ… å¤šç»´åº¦æ€§èƒ½æŒ‡æ ‡
- âœ… å¯è§†åŒ–åˆ†æ
- âœ… é²æ£’æ€§æµ‹è¯•
- âœ… æ¨¡å‹å¯¹æ¯”å®éªŒ

ä½¿ç”¨è¿™äº›å·¥å…·å¯ä»¥å…¨é¢äº†è§£BERTæ¨¡å‹åœ¨æƒ…æ„Ÿåˆ†ç±»ä»»åŠ¡ä¸Šçš„è¡¨ç°ï¼Œå¹¶ä¸ä¼ ç»Ÿæ–¹æ³•è¿›è¡Œå…¬å¹³å¯¹æ¯”ã€‚
