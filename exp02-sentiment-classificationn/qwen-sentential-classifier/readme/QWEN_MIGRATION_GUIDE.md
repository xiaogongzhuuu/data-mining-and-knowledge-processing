# ä»BERTè¿ç§»åˆ°Qwenæ¨¡å‹æŒ‡å—

## ğŸ“‹ å¿«é€Ÿæ£€æŸ¥æ¸…å•

åœ¨ä¿®æ”¹ä»£ç ä¹‹å‰ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š

### 1ï¸âƒ£ è¿è¡Œå…¼å®¹æ€§æ£€æŸ¥

```bash
cd qwen-sentential-classifier
python check_qwen_compatibility.py
```

è¿™ä¸ªè„šæœ¬ä¼šï¼š
- âœ… æµ‹è¯•Qwenæ¨¡å‹æ˜¯å¦èƒ½æ­£å¸¸åŠ è½½
- âœ… æ£€æŸ¥tokenizerå…¼å®¹æ€§
- âœ… éªŒè¯æ¨¡å‹è¾“å‡ºæ ¼å¼
- âœ… è¯„ä¼°å†…å­˜éœ€æ±‚
- âœ… ç»™å‡ºæ¨èé…ç½®

---

## ğŸ”§ éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶

### æ–‡ä»¶1: config.py

**å½“å‰é…ç½®:**
```python
model_name = "bert-base-chinese"
max_seq_length = 64
batch_size = 16
```

**ä¿®æ”¹ä¸ºï¼ˆQwen-1.8B ç¤ºä¾‹ï¼‰:**
```python
model_name = "Qwen/Qwen-1_8B"  # æˆ– "Qwen/Qwen2-1.5B"
max_seq_length = 512  # Qwenæ”¯æŒæ›´é•¿åºåˆ—
batch_size = 8  # æ ¹æ®GPUæ˜¾å­˜è°ƒæ•´
```

**ä¿®æ”¹ä¸ºï¼ˆQwen-7B ç¤ºä¾‹ï¼‰:**
```python
model_name = "Qwen/Qwen-7B"
max_seq_length = 512
batch_size = 4  # 7Bæ¨¡å‹æ›´å¤§ï¼Œéœ€è¦æ›´å°çš„batch_size
```

---

### æ–‡ä»¶2: model.py

**éœ€è¦ä¿®æ”¹çš„åœ°æ–¹:**

åœ¨ç¬¬21è¡Œï¼Œä¿®æ”¹ `from_pretrained` è°ƒç”¨ï¼š

**ä¿®æ”¹å‰:**
```python
self.base_model = AutoModel.from_pretrained(model_name)
```

**ä¿®æ”¹å:**
```python
self.base_model = AutoModel.from_pretrained(
    model_name,
    trust_remote_code=True  # Qwenæ¨¡å‹éœ€è¦è¿™ä¸ªå‚æ•°
)
```

**âœ… å¥½æ¶ˆæ¯**: model.py çš„ forward æ–¹æ³•å·²ç»å¤„ç†äº† Qwen æ²¡æœ‰ pooler_output çš„æƒ…å†µï¼ˆç¬¬49-53è¡Œï¼‰ï¼Œä¸éœ€è¦é¢å¤–ä¿®æ”¹ï¼

---

### æ–‡ä»¶3: main.py

**éœ€è¦ä¿®æ”¹çš„åœ°æ–¹:**

åœ¨ç¬¬91è¡Œï¼Œä¿®æ”¹ tokenizer åŠ è½½ï¼š

**ä¿®æ”¹å‰:**
```python
tokenizer = AutoTokenizer.from_pretrained(config.model_name)
```

**ä¿®æ”¹å:**
```python
tokenizer = AutoTokenizer.from_pretrained(
    config.model_name,
    trust_remote_code=True  # Qwenæ¨¡å‹éœ€è¦è¿™ä¸ªå‚æ•°
)
```

åœ¨ç¬¬177è¡Œï¼ˆpredictå‡½æ•°ä¸­ï¼‰ï¼ŒåŒæ ·ä¿®æ”¹ï¼š

**ä¿®æ”¹å‰:**
```python
tokenizer = AutoTokenizer.from_pretrained(config.model_name)
```

**ä¿®æ”¹å:**
```python
tokenizer = AutoTokenizer.from_pretrained(
    config.model_name,
    trust_remote_code=True
)
```

---

### æ–‡ä»¶4-8: å®éªŒè„šæœ¬ï¼ˆå¯é€‰ä½†æ¨èï¼‰

æ‰€æœ‰å®éªŒè„šæœ¬ä¸­åŠ è½½ tokenizer å’Œ model çš„åœ°æ–¹éƒ½éœ€è¦æ·»åŠ  `trust_remote_code=True`ï¼š

**éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶:**
- compare_trained_untrained.py
- sample_stability_analysis.py
- train_size_analysis.py
- epoch_analysis.py

**åœ¨è¿™äº›æ–‡ä»¶ä¸­æ‰¾åˆ°å¹¶ä¿®æ”¹:**
```python
# ä¿®æ”¹tokenizeråŠ è½½
tokenizer = AutoTokenizer.from_pretrained(
    config.model_name,
    trust_remote_code=True
)

# å¦‚æœæœ‰ç›´æ¥åŠ è½½AutoModelçš„åœ°æ–¹ï¼Œä¹Ÿè¦æ·»åŠ 
model = AutoModel.from_pretrained(
    config.model_name,
    trust_remote_code=True
)
```

---

## ğŸ¯ æ¨èçš„Qwenæ¨¡å‹é€‰æ‹©

| æ¨¡å‹ | å‚æ•°é‡ | æ˜¾å­˜éœ€æ±‚ | æ¨èbatch_size | é€‚ç”¨åœºæ™¯ |
|------|--------|---------|---------------|---------|
| Qwen/Qwen-1_8B | 1.8B | ~8GB | 8-16 | èµ„æºå—é™ã€å¿«é€Ÿå®éªŒ |
| Qwen/Qwen2-1.5B | 1.5B | ~6GB | 16 | æœ€è½»é‡çº§ |
| Qwen/Qwen-7B | 7B | ~28GB | 2-4 | è¿½æ±‚æ€§èƒ½ |
| Qwen/Qwen2-7B | 7B | ~28GB | 2-4 | Qwen2ç³»åˆ—ï¼Œæ›´æ–° |

**å»ºè®®**:
- **å¦‚æœæ˜¯å­¦ä¹ /å®éªŒ**: ä½¿ç”¨ Qwen-1.8B æˆ– Qwen2-1.5B
- **å¦‚æœè¿½æ±‚æ€§èƒ½**: ä½¿ç”¨ Qwen-7Bï¼ˆéœ€è¦è¾ƒå¥½çš„GPUï¼‰

---

## âš™ï¸ å®Œæ•´ä¿®æ”¹æ­¥éª¤

### æ­¥éª¤1: æ£€æŸ¥å…¼å®¹æ€§

```bash
python check_qwen_compatibility.py
```

é€‰æ‹©ä½ æƒ³ä½¿ç”¨çš„Qwenæ¨¡å‹ï¼ŒæŸ¥çœ‹æ£€æŸ¥ç»“æœã€‚

### æ­¥éª¤2: ä¿®æ”¹config.py

```bash
# ç›´æ¥ä¿®æ”¹ï¼Œæˆ–ä½¿ç”¨ä¸‹é¢çš„å‘½ä»¤
nano config.py  # æˆ– vim/vscode
```

ä¿®æ”¹ `model_name` ä¸ºä½ é€‰æ‹©çš„Qwenæ¨¡å‹ã€‚

### æ­¥éª¤3: æ‰¹é‡ä¿®æ”¹å…¶ä»–æ–‡ä»¶

æˆ‘å¯ä»¥ä¸ºä½ åˆ›å»ºä¸€ä¸ªè‡ªåŠ¨ä¿®æ”¹è„šæœ¬ï¼Œæˆ–è€…ä½ å¯ä»¥æ‰‹åŠ¨ä¿®æ”¹æ¯ä¸ªæ–‡ä»¶ä¸­çš„ `from_pretrained` è°ƒç”¨ã€‚

### æ­¥éª¤4: æµ‹è¯•è¿è¡Œ

```bash
# å…ˆç”¨å°æ ·æœ¬æµ‹è¯•
python main.py
```

è§‚å¯Ÿæ˜¯å¦æœ‰é”™è¯¯ã€‚

### æ­¥éª¤5: è¿è¡Œå®éªŒ

```bash
./run_all_experiments.sh
```

---

## â— å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### é—®é¢˜1: ImportError: trust_remote_code

**é”™è¯¯ä¿¡æ¯:**
```
ValueError: ... requires you to execute the modeling file ... set `trust_remote_code=True`
```

**è§£å†³æ–¹æ¡ˆ:**
ç¡®ä¿æ‰€æœ‰ `from_pretrained` éƒ½æ·»åŠ äº† `trust_remote_code=True`

---

### é—®é¢˜2: æ˜¾å­˜ä¸è¶³ (CUDA out of memory)

**é”™è¯¯ä¿¡æ¯:**
```
RuntimeError: CUDA out of memory
```

**è§£å†³æ–¹æ¡ˆ:**
1. å‡å° `batch_size` (å¦‚ä»16æ”¹ä¸º4)
2. å‡å° `max_seq_length` (å¦‚ä»512æ”¹ä¸º256)
3. ä½¿ç”¨æ›´å°çš„Qwenæ¨¡å‹
4. ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ï¼š
   ```python
   accumulation_steps = 4  # åœ¨è®­ç»ƒå¾ªç¯ä¸­æ·»åŠ 
   ```

---

### é—®é¢˜3: æ¨¡å‹ä¸‹è½½æ…¢

**è§£å†³æ–¹æ¡ˆ:**
ä»£ç å·²ç»è®¾ç½®äº†é•œåƒï¼š
```python
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
```

å¦‚æœè¿˜æ˜¯æ…¢ï¼Œå¯ä»¥æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹ï¼š
```bash
# ä½¿ç”¨huggingface-cli
pip install huggingface_hub
huggingface-cli download Qwen/Qwen-1_8B --local-dir ./models/qwen-1.8b
```

ç„¶åä¿®æ”¹ config.py:
```python
model_name = "./models/qwen-1.8b"
```

---

### é—®é¢˜4: æ¨¡å‹è¾“å‡ºç»´åº¦ä¸åŒ¹é…

**é”™è¯¯ä¿¡æ¯:**
```
RuntimeError: mat1 and mat2 shapes cannot be multiplied
```

**è§£å†³æ–¹æ¡ˆ:**
è¿™ä¸åº”è¯¥å‘ç”Ÿï¼Œå› ä¸ºåˆ†ç±»å™¨ä¼šæ ¹æ® `model.config.hidden_size` è‡ªåŠ¨é€‚é…ã€‚

å¦‚æœå‡ºç°ï¼Œæ£€æŸ¥ï¼š
1. æ˜¯å¦æ­£ç¡®åŠ è½½äº†æ¨¡å‹
2. config.py ä¸­çš„ model_name æ˜¯å¦æ­£ç¡®

---

## ğŸ” éªŒè¯ä¿®æ”¹æ˜¯å¦æ­£ç¡®

è¿è¡Œè¿™ä¸ªç®€å•æµ‹è¯•ï¼š

```python
from config import Config
from transformers import AutoTokenizer, AutoModel

config = Config()

# æµ‹è¯•tokenizer
tokenizer = AutoTokenizer.from_pretrained(
    config.model_name,
    trust_remote_code=True
)
print(f"âœ… TokenizeråŠ è½½æˆåŠŸ")

# æµ‹è¯•model
model = AutoModel.from_pretrained(
    config.model_name,
    trust_remote_code=True
)
print(f"âœ… ModelåŠ è½½æˆåŠŸ")
print(f"Hidden size: {model.config.hidden_size}")
```

å¦‚æœéƒ½æˆåŠŸï¼Œè¯´æ˜é…ç½®æ­£ç¡®ï¼

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”é¢„æœŸ

ä»BERT-base-chineseè¿ç§»åˆ°Qwenåï¼Œä½ å¯èƒ½ä¼šçœ‹åˆ°ï¼š

| æŒ‡æ ‡ | BERT-base-chinese | Qwen-1.8B | Qwen-7B |
|------|-------------------|-----------|---------|
| å‡†ç¡®ç‡ | ~85-88% | ~88-90% | ~90-92% |
| è®­ç»ƒæ—¶é—´/epoch | 1x | 1.2-1.5x | 2-3x |
| æ˜¾å­˜å ç”¨ | ~4GB | ~8GB | ~28GB |
| æ¨ç†é€Ÿåº¦ | 1x | 0.8x | 0.3x |

**æ³¨**: å…·ä½“æ•°å€¼å–å†³äºæ•°æ®é›†å’Œç¡¬ä»¶

---

## ğŸ“ ä¸‹ä¸€æ­¥

1. âœ… è¿è¡Œ `check_qwen_compatibility.py` æ£€æŸ¥å…¼å®¹æ€§
2. âœ… æ ¹æ®å»ºè®®ä¿®æ”¹ config.py
3. âœ… ä¿®æ”¹ model.py å’Œ main.py æ·»åŠ  `trust_remote_code=True`
4. âœ… å¯é€‰ï¼šä¿®æ”¹å®éªŒè„šæœ¬
5. âœ… è¿è¡Œ `python main.py` æµ‹è¯•è®­ç»ƒ
6. âœ… è¿è¡Œå®éªŒè„šæœ¬éªŒè¯

---

**éœ€è¦å¸®åŠ©ï¼Ÿ**
- è¿è¡Œå…¼å®¹æ€§æ£€æŸ¥è„šæœ¬ä¼šç»™å‡ºè¯¦ç»†å»ºè®®
- å¦‚æœé‡åˆ°é”™è¯¯ï¼ŒæŸ¥çœ‹"å¸¸è§é—®é¢˜"éƒ¨åˆ†
- å¯ä»¥å…ˆåœ¨å°æ•°æ®é›†ä¸Šæµ‹è¯•ï¼ˆä¿®æ”¹ config.py çš„ max_train_samplesï¼‰
